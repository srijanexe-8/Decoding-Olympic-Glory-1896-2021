{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e556b7",
   "metadata": {},
   "source": [
    "# Olympic Medal Prediction Models\n",
    "\n",
    "This notebook demonstrates building and evaluating multiple classification models to predict whether an athlete wins a medal based on demographic and categorical features.  \n",
    "We will compare Logistic Regression, Random Forest, and XGBoost, then save the best-performing model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3762b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7f3a98",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f607dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/olympics_data.csv')\n",
    "df['Medal_Won'] = df['Medal'].notnull().astype(int)\n",
    "df_model = df.dropna(subset=['Age', 'Sex', 'NOC', 'Sport'])\n",
    "X = df_model[['Age', 'Sex', 'NOC', 'Sport']]\n",
    "y = df_model['Medal_Won']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb63ba7",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We include the following features:\n",
    "- `Age`: Athlete's age  \n",
    "- `Sex`: Athlete's gender  \n",
    "- `NOC`: Country code  \n",
    "- `Sport`: Event sport  \n",
    "\n",
    "We will encode categorical variables using `LabelEncoder`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f41e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model[['Age', 'Sex', 'NOC', 'Sport']]\n",
    "y = df_model['Medal_Won']\n",
    "le = LabelEncoder()\n",
    "X['Sex']   = le.fit_transform(X['Sex'])\n",
    "X['NOC']   = le.fit_transform(X['NOC'])\n",
    "X['Sport'] = le.fit_transform(X['Sport'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8d7319",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "Split the data into training and testing sets (70% train, 30% test) to evaluate model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4739487",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e606ae",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "We train three models:\n",
    "1. **Logistic Regression**  \n",
    "2. **Random Forest**  \n",
    "3. **XGBoost**  \n",
    "\n",
    "For each model, we fit on training data and compute accuracy on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daf0ad40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8523\n",
      "Random Forest Accuracy: 0.8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91962\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [02:49:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8670\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f'Logistic Regression Accuracy: {acc_lr:.4f}')\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f'Random Forest Accuracy: {acc_rf:.4f}')\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f'XGBoost Accuracy: {acc_xgb:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caab733",
   "metadata": {},
   "source": [
    "## Compare Models and Save Best\n",
    "\n",
    "Create a summary table of accuracies and save the model with the highest score using `joblib`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b30f99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: XGBoost with accuracy 0.8670\n",
      "Best model saved to ../model/best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    'Logistic Regression': acc_lr,\n",
    "    'Random Forest':        acc_rf,\n",
    "    'XGBoost':              acc_xgb\n",
    "}\n",
    "best_model_name = max(results, key=results.get)\n",
    "print(f\"Best Model: {best_model_name} with accuracy {results[best_model_name]:.4f}\")\n",
    "\n",
    "# Map names to objects and save\n",
    "models = {\n",
    "    'Logistic Regression': lr,\n",
    "    'Random Forest':        rf,\n",
    "    'XGBoost':              xgb\n",
    "}\n",
    "best_model = models[best_model_name]\n",
    "import os\n",
    "os.makedirs('../model', exist_ok=True)\n",
    "joblib.dump(best_model, '../model/best_model.pkl')\n",
    "print('Best model saved to ../model/best_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a002a56e",
   "metadata": {},
   "source": [
    "## Detailed Classification Report for Best Model\n",
    "\n",
    "Inspect precision, recall, and F1-score to understand model performance across classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "574b4828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93     66901\n",
      "           1       0.70      0.17      0.27     11592\n",
      "\n",
      "    accuracy                           0.87     78493\n",
      "   macro avg       0.79      0.58      0.60     78493\n",
      "weighted avg       0.85      0.87      0.83     78493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[66072   829]\n",
      " [ 9614  1978]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_best))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
